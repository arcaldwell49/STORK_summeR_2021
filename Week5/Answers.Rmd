---
title: 'Week 5: Correlations, t-tests, ANOVAs, oh my!'
author: "Aaron R. Caldwell"
output: 
  github_document:
    toc: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
library(tidyverse)
```

# Week 5 Answers

This week's instructions were written in R now that everyone is aware of how to use Rmarkdown.

Now we get down to what R was created for: statistics. 

# Useful Packages

```{r}
# statistics packages
# functions simliar to tidyverse
# install.packages("easystats", repos = "https://easystats.r-universe.dev")
library(easystats)

# For ANOVAs
library(afex)

# For equivalence testing
# Download the developmental version
# devtools::install_github("arcaldwell49/TOSTER")
library(TOSTER)
```

Now, let's import the data we need for this week!

```{r}
data("sleep")
data("ChickWeight")
data("iris")
```

\newpage

# Correlations

> Let's assume you are a botanist and are interested in the relationship between different measures of flower size. You are going to use the `iris` dataset to determine the correlation between 4 different meaures: sepal length, sepal width, petal length, and petal width.

This process isn't too difficult with the `correlation` package, but we could just as easily use the base version function `cor` or `cor.test`.

```{r}
# First remove the species column
iris2 = iris %>%
  select(-Species)

correlation(iris2,
            method = "Pearson") %>%
  knitr::kable(caption = "Correlation: Pearson Coefficient")
```

\newpage

```{r}
correlation(iris2,
            method = "Spearman") %>%
  knitr::kable(caption = "Correlation: Spearman Coefficient")
```

\newpage

We can also plot the results to visualize the relationship.

```{r}
correlation(iris2,
            method = "Spearman") %>%
  summary()%>%
  plot(show_values = TRUE, show_p = TRUE, show_legend = FALSE)
```

\newpage

Fun note: you can even plot the *partial* correlations.

```{r}
# You will need ggpraph
library(ggraph)
correlation(iris2,
            partial = TRUE) %>%
  plot()
```

\newpage

## Base R approach

As I mentioned before you can use the `cor.test` is there is a particular correlation you want to test. This is useful if you do not want to create a matrix of results.

As an example, let's use `cor.test` to test the relationship between sepal length and petal length.

```{r}
sepal_length = iris$Sepal.Length
petal_length = iris$Petal.Length
test1 = cor.test(sepal_length,petal_length)
# Now we can print the result
test1

```

However, we can also use the `report` package to get a summary of the result.

```
report(test1)
```

`r report(test1)`


# t-test

> Let's compare the groups (i.e., drug) in the "sleep" dataset and see if there is a difference in the hours of sleep each night 

So, in this scenario you are trying to test if there are difference between two treatments. Let's check the data and see what it looks like.

```{r}
knitr::kable(sleep)
```

Notice how the ID repeats between treatments? That means we have a *paired* sample; meaning that each participant was exposed to **both** conditions. This means we will use a paired samples t-test to test for differences in the mean increase in the hours of sleep (`extra`).

Luckily, R makes this easy with the built in `t.test` function.

```{r}
# formula approach
ttest1 = t.test(extra ~ group,
                data = sleep,
                paired = TRUE)

# 2 vector approach

ttest2 = t.test(x = subset(sleep, group ==1)$extra,
                y = subset(sleep, group ==2)$extra,
                paired = TRUE)

ttest1
```

Again, we can use the `report` function to get a tidy text output

```
report(ttest1)
```

`r report(ttest1)`

## Non-parametric tests

Sometimes we the assumptions of a t-test (e.g., normal residuals) are not tenable. In these situations we can use a non-parametric test like the Wilcoxon signed rank test (test of ranks).

The `wilcox.test` function performs this analysis and works just like the `t.test` function.

```{r}
# formula approach
wtest1 = wilcox.test(extra ~ group,
                data = sleep,
                paired = TRUE)

# 2 vector approach

wtest2 = wilcox.test(x = subset(sleep, group ==1)$extra,
                y = subset(sleep, group ==2)$extra,
                paired = TRUE)

wtest1
```


The report function does not work for this type of result at this time, but you can get an effect size measure (rank-biserial correlation) from the `effectsize package`.

```{r}
effectsize::rank_biserial(subset(sleep, group == 1)$extra,
                          subset(sleep, group == 2)$extra)
```


## Equivalence Test

Let's say we are interested in equivalence. For example, we may have developed a new drug and want to make sure it equivalent to the old drug when it comes to extra hours of sleep. That is where the `TOSTER` package and the new `t_TOST` function can be useful. The setup is almost exactly the same; but we just going to set upper and lower equivalence bounds.

```{r}
# remember library(TOSTER)

TOSTsleep = t_TOST(
  extra ~ group,
  data = sleep,
  low_eqbound = -1,
  high_eqbound = 1,
  paired = TRUE
)

TOSTsleep

plot(TOSTsleep)
```

# ANOVA

> Suppose you are an animal scientist and you have data on different diets fed to chickens over 21 weeks. Let's assume the scientist wants to test if the weight of the chicks is moderated by diet over time

As with many things in R there are literally dozens of ways to run an ANOVA. The main issue is that many of the options, like base R's `aov` function, are limited in scope (e.g., don't handle within subjects factors appropriately). This is where the `afex` R package (afex = "Analysis of Factorial Experiments") can be very useful. It essentially makes the process of performing and reporting an ANOVA much easier for the average R user.

For this particular test, we have data that is in long format and is repeated measures. We need our model to include a within subjects factor, `Time`, across chicks, `Chick`, and include a between subjects interaction for diet, `Diet`, for the outcome variable (`weight`).

For `afex`, there are three different functions that can provide the solution: `aov_ez`, `aov_car`, and `aov_4`. My preference is `aov_4` because it functions similarly to other functions that involve linear mixed models (so it is easier for me to conceptualize).

The first is `aov_ez` where we can tell the function our id variable (`Chick`), the dependent variable (`weight`), and the we specifically specify the data, between subjects variables, and within subjects variables. Lastly, I specify that I want the partial eta-squared.

```{r}
a1 <- aov_ez(
  id = "Chick",
  dv = "weight",
  data = ChickWeight,
  between = "Diet",
  within = c("Time"),
  anova_table = list(es = "pes")
)
a1
```

The same process can be completed with the `aov_car` function but I have to specify the error term.

```{r}
a2 <- aov_car(weight ~ Diet + Error(Chick / Time),
              data = ChickWeight,
              anova_table = list(es = "pes"))
a2
```

Lastly, there is `aov_4` which uses a format very similar to the mixed models functions in R (random/within separated by `|` for the id variable.
```{r}
a3 <- aov_4(weight ~ Diet + (Time|Chick),
              data = ChickWeight,
              anova_table = list(es = "pes"))
a3
```


However, let's plot the residuals of the data to see if our assumptions are met. We can see from the plots below that the residuals are leptokurtic and heteroskedasticity is extreme.

```{r}
# Get residuals
d1 = residuals(a3,
               append = TRUE,
               colname_residuals = "resid") %>%
  as_tibble()

# Get fitte values
d2 = fitted(a3,
               append = TRUE,
               colname_fitted = "fitted") %>%
  as_tibble()

# Put together
d1$fitted = d2$fitted 
d1 = d1 %>%  mutate(std_resid = resid / sd(resid))
  

ggplot(d1,
       aes(x=resid)) +
  geom_density() +
  theme_bw() +
  labs(title = "Residuals")

ggplot(d1,
       aes(y=sqrt(abs(std_resid)),
           x = fitted)) +
  geom_point() +
  geom_smooth(method="loess",
              formula = y ~ x) +
  theme_bw() +
  labs(title = "Homogeneity of Variance")


```

Therefore, we can transform the data to "normalize" the residuals. We can see here that the repeated measures ANOVA still doesn't quite meet our assumptions tests, but it probably wouldn't be tragic to use this model either. However, please not that time is being treated as a continuous variable which is wildly inefficient.

```{r}

a4 = aov_4(
  sqrt(weight) ~ Diet + (Time | Chick),
  data = ChickWeight,
  anova_table = list(es = "pes"))

```

```{r}
# Get residuals
d1 = residuals(a4,
               append = TRUE,
               colname_residuals = "resid") %>%
  as_tibble()

# Get fitte values
d2 = fitted(a4,
               append = TRUE,
               colname_fitted = "fitted") %>%
  as_tibble()

# Put together
d1$fitted = d2$fitted 
d1 = d1 %>%  mutate(std_resid = resid / sd(resid))
  

ggplot(d1,
       aes(x=resid)) +
  geom_density() +
  theme_bw() +
  labs(title = "Residuals")

ggplot(d1,
       aes(y=sqrt(abs(std_resid)),
           x = fitted)) +
  geom_point() +
  geom_smooth(method="loess",
              formula = y ~ x) +
  theme_bw() +
  labs(title = "Homogeneity of Variance")

afex_plot(a4,
          x = "Time",
          trace = "Diet",
          panel = "Diet",
          data_plot = FALSE)
```

## Additional Analysis

```{r}
ChickWeight %>%
  drop_na() %>%
ggplot(aes(x=Time,
           y=weight,
           color = Chick))+
  geom_point(alpha = .1) +
  geom_smooth(method = "lm",
              formula = y~x,
              se = FALSE) +
  scale_color_viridis_d(option = "plasma") +
  facet_wrap(~Diet, labeller = "label_both") +
  theme_bw() +
  theme(legend.position = "none") 
```


```{r}
library(lme4)

lmer_raw = lmer(weight ~ Diet*as.numeric(Time)+(Time|Chick),
                data = ChickWeight)

anova(lmer_raw) %>%
  knitr::kable()

dat_resid = ChickWeight %>%
  mutate()
```

```{r}
# Check normality
check <- check_normality(lmer_raw)
plot(check, type = "qq")
plot(check)
# Check Variance
check2 <- check_heteroscedasticity(lmer_raw)

plot(check2)
```

```{r}
lmer_sq = lmer(sqrt(weight) ~ Diet*as.numeric(Time)+(Time|Chick),
                data = ChickWeight)

anova(lmer_sq) %>%
  knitr::kable()
```


```{r}
# Check normality
check <- check_normality(lmer_sq)
plot(check, type = "qq")
plot(check)
plot(check_normality(lmer_sq, effects = "random"))
# Check Variance
check2 <- check_heteroscedasticity(lmer_sq)

plot(check2)
```


```{r}
library(emmeans)
emtrends(lmer_sq, pairwise ~ Diet, var = "Time",
         adjust = "holm")

emmip(lmer_sq, Diet ~ Time, cov.reduce = range) +
  theme_classic() +
  scale_color_viridis_d(option = "plasma")
  
```

```{r}
library(interactions)
interact_plot(lmer_sq, pred = Time, modx = Diet, interval = TRUE,
              int.width = 0.8,
              data = ChickWeight)

ss <- sim_margins(lmer_sq, pred = Time, modx = Diet)
plot(ss)
```

